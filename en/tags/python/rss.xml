<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Python on yshalsager</title><link>https://yshalsager.com/en/tags/python/</link><description>Latest posts from in Python yshalsager</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Copyright Â© 2013-{year} yshalsager. All Rights Reserved.</copyright><lastBuildDate>Mon, 28 Nov 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://yshalsager.com/en/tags/python/rss.xml" rel="self" type="application/rss+xml"/><item><title>Using Parsel instead of Beautiful Soup for Web Scraping</title><link>https://yshalsager.com/en/posts/using-parsel-instead-of-beautiful-soup-for-web-scraping/</link><pubDate>Mon, 28 Nov 2022 00:00:00 +0000</pubDate><guid>https://yshalsager.com/en/posts/using-parsel-instead-of-beautiful-soup-for-web-scraping/</guid><description>&lt;p>&lt;a href="https://en.wikipedia.org/wiki/Web_scraping" target="_blank" rel="noopener noreferrer">Web scraping&lt;i class="fas fa-external-link-square-alt ms-1">&lt;/i>&lt;/a> is an automated process to extract data from web page, and since &lt;a href="https://www.python.org/" target="_blank" rel="noopener noreferrer">Python&lt;i class="fas fa-external-link-square-alt ms-1">&lt;/i>&lt;/a> is one the most popular programming languages it&amp;rsquo;s common to see people use it for doing web scraping tasks like me :)&lt;/p>
&lt;p>For a long time, I have been using &lt;a href="http://www.crummy.com/software/BeautifulSoup/" target="_blank" rel="noopener noreferrer">Beautiful Soup 4&lt;i class="fas fa-external-link-square-alt ms-1">&lt;/i>&lt;/a> to extract data from web pages&amp;rsquo; HTML markup, it&amp;rsquo;s popular, easy, robust, and battle-tested library for navigating, searching, and modifying the &lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/Document_Object_Model/Introduction" target="_blank" rel="noopener noreferrer">DOM&lt;i class="fas fa-external-link-square-alt ms-1">&lt;/i>&lt;/a> tree. But, recently I came across &lt;a href="https://github.com/scrapy/parsel" target="_blank" rel="noopener noreferrer">Parsel&lt;i class="fas fa-external-link-square-alt ms-1">&lt;/i>&lt;/a>, another HTML parsing library that supports &lt;a href="https://developer.mozilla.org/en-US/docs/Web/XPath" target="_blank" rel="noopener noreferrer">XPath&lt;i class="fas fa-external-link-square-alt ms-1">&lt;/i>&lt;/a> selectors, which is missing in Beautiful Soup, and I was in need of using something that can extract data from HTML using XPath (rather than &lt;a href="https://scrapy.org/" target="_blank" rel="noopener noreferrer">Scrapy&lt;i class="fas fa-external-link-square-alt ms-1">&lt;/i>&lt;/a>, funny enough, later I knew that Scrapy uses Parsel under the hood :D), so I decided to get it a try.&lt;/p>
&lt;h2 id="thoughts-and-tricks-after-usage" data-numberify>Thoughts and Tricks After Usage&lt;a class="anchor ms-1" href="#thoughts-and-tricks-after-usage">&lt;/a>&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>Parsel is so powerful! it saved me much time than bs4 usually did, this is mainly because of the easy way it provides to access &lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/Node" target="_blank" rel="noopener noreferrer">DOM Node&lt;i class="fas fa-external-link-square-alt ms-1">&lt;/i>&lt;/a> HTML, text, attributes and other values easily with a handy way to get a default value if the required data didn&amp;rsquo;t exist.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Parsel uses &lt;a href="https://lxml.de/" target="_blank" rel="noopener noreferrer">lxml&lt;i class="fas fa-external-link-square-alt ms-1">&lt;/i>&lt;/a> for parsing the web page, this can result in a huge performance improvement according to &lt;a href="https://github.com/rushter/selectolax#simple-benchmark" target="_blank" rel="noopener noreferrer">selectolax&amp;rsquo;s benchmark&lt;i class="fas fa-external-link-square-alt ms-1">&lt;/i>&lt;/a> (which is an interesting library to try as well).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Parsel is easy to use, all you need to do is to import &lt;code>Selector&lt;/code> from &lt;code>parsel&lt;/code> package then use &lt;code>Selector(text=response.text)&lt;/code> to load HTML string into a selector object.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="ln">1&lt;/span>&lt;span class="cl">&lt;span class="c1"># code snippet from https://parsel.readthedocs.io/en/latest/usage.html &lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="ln">2&lt;/span>&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">parsel&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">Selector&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="ln">3&lt;/span>&lt;span class="cl">&lt;span class="n">text&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;&amp;lt;html&amp;gt;&amp;lt;body&amp;gt;&amp;lt;h1&amp;gt;Hello, Parsel!&amp;lt;/h1&amp;gt;&amp;lt;/body&amp;gt;&amp;lt;/html&amp;gt;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="ln">4&lt;/span>&lt;span class="cl">&lt;span class="n">selector&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Selector&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">text&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">text&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>
&lt;p>&lt;code>.getall()&lt;/code> and &lt;code>.get()&lt;/code> are equivalent for &lt;code>.select()&lt;/code>and &lt;code>.select_one()&lt;/code> in bs4.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>.xpath()&lt;/code> and &lt;code>.css()&lt;/code> methods can be chained! &lt;code>selector.css('img').xpath('@src').getall()&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>Selector&lt;/code>&amp;rsquo;s non-standard &lt;code>::text&lt;/code> pseudo-element can be better than Beautiful Soup&amp;rsquo;s &lt;code>.text&lt;/code> because it won&amp;rsquo;t be &lt;code>None&lt;/code> even with empty text. Same goes for &lt;code>::attr&lt;/code> vs &lt;code>.get()&lt;/code> (without default value).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Use &lt;code>*::text&lt;/code> to selects all descendant text nodes of the current selector.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>If you want to use &lt;a href="https://en.wikipedia.org/wiki/Regular_expression" target="_blank" rel="noopener noreferrer">regular expressions&lt;i class="fas fa-external-link-square-alt ms-1">&lt;/i>&lt;/a> (regex) to get data from a string of a selector, all you need to do is to use &lt;code>.re()&lt;/code> and &lt;code>.re_first()&lt;/code> methods. However, unlike using &lt;code>.xpath()&lt;/code> or &lt;code>.css()&lt;/code> methods, regex methods returns a list of strings so they can&amp;rsquo;t be chained.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The proper way to work with relative XPaths is to prefix the path with dot &lt;code>divs.xpath('.//p')&lt;/code>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>drop()&lt;/code> can be used to remove elements based on a Selector, this is similar to &lt;code>Tag.decompose()&lt;/code> in bs4, and can&amp;rsquo;t be undone.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>When querying by class, consider using CSS instead of XPath.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>You can convert CSS to XPath using Parsel&amp;rsquo;s &lt;code>css2xpath&lt;/code> function.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Because of lxml, sometimes you may get something rather that what browser show while parsing the HTML using Parsel, here are &lt;a href="https://github.com/scrapy/parsel/issues/83" target="_blank" rel="noopener noreferrer">more details&lt;i class="fas fa-external-link-square-alt ms-1">&lt;/i>&lt;/a> about this issue.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="extra-resources" data-numberify>Extra Resources&lt;a class="anchor ms-1" href="#extra-resources">&lt;/a>&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://devhints.io/css" target="_blank" rel="noopener noreferrer">CSS cheatsheet&lt;i class="fas fa-external-link-square-alt ms-1">&lt;/i>&lt;/a> that has good summary of CSS selectors.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://devhints.io/xpath" target="_blank" rel="noopener noreferrer">Xpath cheatsheet&lt;i class="fas fa-external-link-square-alt ms-1">&lt;/i>&lt;/a>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://scrapinghub.github.io/xpath-playground/" target="_blank" rel="noopener noreferrer">XPath Playground&lt;i class="fas fa-external-link-square-alt ms-1">&lt;/i>&lt;/a> to try out your XPath queries.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="XPath/CSS%20Equivalents">XPath/CSS Equivalents&lt;/a>.&lt;/p>
&lt;/li>
&lt;/ul></description></item><item><title>Debugging and fixing Selenium's send_keys() wrong text input</title><link>https://yshalsager.com/en/posts/debugging-and-fixing-selenium-send-keys-wrong-text-input/</link><pubDate>Mon, 28 Sep 2020 00:00:00 +0000</pubDate><guid>https://yshalsager.com/en/posts/debugging-and-fixing-selenium-send-keys-wrong-text-input/</guid><description>&lt;p>&lt;em>There are many kinds of bugs you may face while programming, but without a doubt, ghost bugs are the worse!&lt;/em>&lt;/p>
&lt;p>I recently faced a weird problem while working on a freelance &lt;a href="https://www.selenium.dev/" target="_blank" rel="noopener noreferrer">Selenium&lt;i class="fas fa-external-link-square-alt ms-1">&lt;/i>&lt;/a> (A portable framework for testing web applications) project in Python which is: &lt;a href="https://selenium-python.readthedocs.io/api.html?highlight=execute_script#selenium.webdriver.remote.webelement.WebElement.send_keys" target="_blank" rel="noopener noreferrer">send_keys&lt;i class="fas fa-external-link-square-alt ms-1">&lt;/i>&lt;/a> method is sending random wrong input. Here are the details of the problem, how did I debug it, and how I managed to fix after hours of investigating!&lt;/p>
&lt;p>I have been working on a freelance Selenium web automation and scraping project and we need to move the script to a better Linux server that runs Ubuntu 20.04. After migrating I found out that Selenium text input became so random (although it works perfectly on local PCs). For example, spaces are no longer sent, numbers are mixed, some characters are dropped, and so forth.&lt;/p>
&lt;p>I started to debug with &lt;a href="https://python.org" target="_blank" rel="noopener noreferrer">Python&lt;i class="fas fa-external-link-square-alt ms-1">&lt;/i>&lt;/a>&amp;rsquo;s &lt;a href="https://docs.python.org/3/library/logging.html" target="_blank" rel="noopener noreferrer">logging&lt;i class="fas fa-external-link-square-alt ms-1">&lt;/i>&lt;/a> standard module, but the log said that the correct input was being entered, which is logical since no code changes happened. Then, I tried to see if there&amp;rsquo;s something wrong with &lt;a href="https://chromedriver.chromium.org/" target="_blank" rel="noopener noreferrer">chromedriver&lt;i class="fas fa-external-link-square-alt ms-1">&lt;/i>&lt;/a> that being used to automate Google Chrome browser, but again, version on the old and new servers was the same. I have also tried on another (third) server that runs Ubuntu 18.04 and the same bug occurred. It&amp;rsquo;s Google and &lt;a href="https://stackoverflow.com" target="_blank" rel="noopener noreferrer">stackoverflow&lt;i class="fas fa-external-link-square-alt ms-1">&lt;/i>&lt;/a> time! I searched our beloved websites to see if any people faced this problem besides me. I found many results from 6 years ago till 5 months ago. The most interesting one was a &lt;a href="https://chromedriver.chromium.org/" target="_blank" rel="noopener noreferrer">chromedriver&lt;i class="fas fa-external-link-square-alt ms-1">&lt;/i>&lt;/a>&amp;rsquo;s &lt;a href="https://bugs.chromium.org/p/chromedriver/issues/detail?id=1771" target="_blank" rel="noopener noreferrer">bug&lt;i class="fas fa-external-link-square-alt ms-1">&lt;/i>&lt;/a> that got closed with &lt;code>WontFix&lt;/code> status. This bug aside, the suggested solutions were:&lt;/p>
&lt;ul>
&lt;li>Using &lt;a href="https://selenium-python.readthedocs.io/api.html?highlight=WebElement#selenium.webdriver.remote.webelement.WebElement.clear" target="_blank" rel="noopener noreferrer">clear()&lt;i class="fas fa-external-link-square-alt ms-1">&lt;/i>&lt;/a> method of the &lt;a href="https://selenium-python.readthedocs.io/api.html?highlight=WebElement#module-selenium.webdriver.remote.webelement" target="_blank" rel="noopener noreferrer">WebElement&lt;i class="fas fa-external-link-square-alt ms-1">&lt;/i>&lt;/a> before sending the text input.&lt;/li>
&lt;li>Clicking the text box before sending keys.&lt;/li>
&lt;li>Using &lt;a href="https://selenium-python.readthedocs.io/api.html?highlight=execute_script#webdriver-api" target="_blank" rel="noopener noreferrer">WebDriver&lt;i class="fas fa-external-link-square-alt ms-1">&lt;/i>&lt;/a>&amp;rsquo;s &lt;a href="https://selenium-python.readthedocs.io/api.html?highlight=execute_script#selenium.webdriver.remote.webdriver.WebDriver.execute_script" target="_blank" rel="noopener noreferrer">execute_script()&lt;i class="fas fa-external-link-square-alt ms-1">&lt;/i>&lt;/a> method to execute JavaScript code that modifies the value of the input form to the required text.&lt;/li>
&lt;li>Using &lt;a href="https://docs.python.org/3/library/time.html?highlight=sleep#time.sleep" target="_blank" rel="noopener noreferrer">sleep&lt;i class="fas fa-external-link-square-alt ms-1">&lt;/i>&lt;/a> from &lt;code>time&lt;/code> standard module to wait for seconds between two &lt;code>send_keys()&lt;/code> calls.&lt;/li>
&lt;li>Changing the server&amp;rsquo;s keyboard layout to &lt;code>US&lt;/code>.&lt;/li>
&lt;li>Using &lt;a href="https://github.com/asweigart/pyperclip/" target="_blank" rel="noopener noreferrer">pyperclip&lt;i class="fas fa-external-link-square-alt ms-1">&lt;/i>&lt;/a> module to paste the text into the browser directly.&lt;/li>
&lt;/ul>
&lt;p>But surprisingly, none of the mentioned solutions above did it, so I gave up and planned to switch to Firefox&amp;rsquo;s &lt;a href="https://github.com/mozilla/geckodriver" target="_blank" rel="noopener noreferrer">geckodriver&lt;i class="fas fa-external-link-square-alt ms-1">&lt;/i>&lt;/a> in the next day.&lt;/p>
&lt;p>After starting to add &lt;code>geckodriver&lt;/code> support, I decided to search for a solution again since the code works &lt;strong>perfectly&lt;/strong> on the PC. While reading stackoverflow&amp;rsquo;s solutions my eyes caught a very interesting &lt;a href="https://stackoverflow.com/a/23411005" target="_blank" rel="noopener noreferrer">answer&lt;i class="fas fa-external-link-square-alt ms-1">&lt;/i>&lt;/a>:&lt;/p>
&lt;blockquote>
&lt;p>I also experienced this problem when connecting to a VM using VNC and then running the Selenium test that way.
The VNC was actually the one dropping characters. Once I moved to a direct connection to the VM using the VirtualBox console&amp;hellip; it worked fine.&lt;/p>
&lt;/blockquote>
&lt;p>This sounded very logical to me, so I quickly check what is the used &lt;a href="https://en.wikipedia.org/wiki/Virtual_Network_Computing" target="_blank" rel="noopener noreferrer">VNC&lt;i class="fas fa-external-link-square-alt ms-1">&lt;/i>&lt;/a> on the new server (Ubuntu 20.04) and the third server (Ubuntu 18.04). It was &lt;a href="https://www.tightvnc.com/" target="_blank" rel="noopener noreferrer">TightVNC&lt;i class="fas fa-external-link-square-alt ms-1">&lt;/i>&lt;/a>. The old server VNC was available externally from the service provider so I couldn&amp;rsquo;t check what does it use.&lt;/p>
&lt;p>After more quick googling I found out that &lt;a href="https://tigervnc.org/" target="_blank" rel="noopener noreferrer">TigerVNC&lt;i class="fas fa-external-link-square-alt ms-1">&lt;/i>&lt;/a> should be a good alternative to the current VNC server. Using apt (a package manager for Debian, Ubuntu, and related Linux distributions), I installed &lt;code>tigervnc-standalone-server tigervnc-common tigervnc-xorg-extension&lt;/code> packages and boom! it worked like a charm.&lt;/p>
&lt;p>It was a very weird problem that occurred out of the blue and I took a very long time to figure it out and fix it. Hopes this post helps you if came here for fixing this problem!&lt;/p></description></item></channel></rss>